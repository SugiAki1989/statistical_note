---
title: "StanとRでベイズ統計モデリング03"
pagetitle: "StanとRでベイズ統計モデリング03"
output:
  html_document:
    toc: TRUE
    toc_depth: 5
    toc_float: FALSE
    # number_sections: TRUE
    code_folding: "show"
    highlight: "kate"
    # theme: "flatly"
    css: ../style.css
    md_extensions: -ascii_identifiers
---

```{r SETUP, include = FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  # out.width = 800,
  # out.height = 600,
  fig.align = "center",
  dev = "ragg_png"
)
```

<div class="update-right">
UPDATE: `r Sys.time()`
</div>

# はじめに

このノートは「StanとRでベイズ統計モデリング」の内容を写経することで、ベイズ統計への理解を深めていくために作成している。

- [StanとRでベイズ統計モデリング](https://www.kyoritsu-pub.co.jp/bookdetail/9784320112421)
- [StanとRでベイズ統計モデリング サポートページ](https://github.com/MatsuuraKentaro/RStanBook)

基本的には気になった部分を写経しながら、ところどころ自分用の補足をメモすることで、「StanとRでベイズ統計モデリング」を読み進めるための自分用の補足資料になることを目指す。私の解釈がおかしく、メモが誤っている場合があるので注意。

今回は第5章「基本的な回帰とモデルのチェック」のチャプターの後半(ロジスティック回帰、ポアソン回帰の部分)を写経していく。

## 5.2.3 メカニズムの想像

第5章の後半では一般化線形モデルを扱う。まずは二項ロジスティック回帰モデル。目的変数は`retio=Y/M=出席回数/授業総回数`である。

二項ロジスティック回帰モデルは予測値が(0,1)の範囲を超えないように(-∞,+∞)の範囲で値を取る説明変数を変換する必要がある。一般的にはロジスティック関数$1/\{1 + exp(-x)\}$を利用する。ロジスティック関数はロジット関数の逆関数なので、`inverse_logit`と表記されることもある。

出席確率$q$は、線形結合$b_{1} + b_{2}A[n] + b_{3}Score[n]$をロジスティック関数で変換することで決まり、その$q$をもとに$M,q$をパラメタとする二項分布に従って$Y$が生成されると仮定する。

<div class="tbox">
<th3>モデル5-4</th3>
<div class="inner">
$$
\begin{eqnarray}
q[n] &=& inv\_logit(b_{1} + b_{2}A[n] + b_{3}Score[n])  \\
Y[n] &\sim& Binomial(M[n], q[n])
\end{eqnarray}
$$
</div>
</div>

## 5.2.5 Stanで実装

モデル5-4をStanで実装した例は下記の通り。1人の学生ごとに$inv\_logit(b_{1} + b_{2}A[n] + b_{3}Score[n])$によって変換される`q[n]`と`M[n]`をパラメタとして持つ二項分布から`Y[n]`が生成されると仮定している。

```
data {
  int N;
  int<lower=0, upper=1> A[N];
  real<lower=0, upper=1> Score[N];
  int<lower=0> M[N];
  int<lower=0> Y[N];
}

parameters {
  real b1;
  real b2;
  real b3;
}

transformed parameters {
  real q[N];
  for (n in 1:N){
    q[n] = inv_logit(b1 + b2*A[n] + b3*Score[n]);
  }
}

model {
  for (n in 1:N){
    Y[n] ~ binomial(M[n], q[n]);
  }
}

generated quantities {
  real y_pred[N];
  for (n in 1:N)
    y_pred[n] = binomial_rng(M[n], q[n]);
}
```

Stanモデルの定義も終わっているので、書籍内で使用されているデータを利用して分析を実行する。

```{r}
# パラメタの事後分布をすべて表示するため
# ロジスティック回帰では出席ごとの約2000行のデータを扱うので、
# パラメタの数が非常に多いが、紙面でもないので、全部表示しておく。
options(max.print = 999999)
library(dplyr)
library(ggplot2)
library(rstan)

d <- read.csv('https://raw.githubusercontent.com/MatsuuraKentaro/RStanBook/master/chap05/input/data-attendance-2.txt')
data <- list(N = nrow(d), A = d$A, Score = d$Score/200, M = d$M, Y = d$Y)
head(data)
```

ここでは、`stan_model()`関数で最初にコンパイルしておいてから、

```{r, eval=TRUE, echo=TRUE, results='hide'}
model525 <- stan_model('note_ahirubayes03.stan')
```

`sampling()`関数でサンプリングする。

```{r, eval=TRUE, echo=TRUE, results='hide'}
fit <- sampling(object = model525, data = data, seed = 1234)
```

パラメタの解釈はオッズとなるため注意が必要。

$$
\begin{eqnarray}
q[n] &=& inv\_logit(X) \\
&=& \frac{1}{1+exp(-X)} \\
\end{eqnarray}
$$

さらに変化を進めるとオッズが出てくる。

$$
\begin{eqnarray}
\frac{q}{1-q} &=& exp(-X)\\
\end{eqnarray}
$$

推定結果は下記の通り。

```{r, class.output="scroll-1000"}
print(fit, prob = c(0.025, 0.5, 0.975), digits_summary = 1)
```

## 5.2.7 図によるモデルのチェック

二項ロジステイック回帰でも重回帰のときと同様に、各学生ごとに観測値と予測分布の散布図を書くことでモデルの予測性能の良し悪しを確認できる。`ms$y_pred`にはMCMCサンプル数4000行、学生50人分の予測分布が保存されているので、パーセンタイルを計算して可視化する。書籍の図に`facet_grid(~A)`を追加しているが、`A=0`の場合、観測値が大きいところで、予測分布が`y=x`を含まないケースが多い模様。

```{r}
ms <- rstan::extract(fit)

qua <- apply(ms$y_pred, 2, quantile, prob = c(0.1, 0.5, 0.9))
d_est <- data.frame(d, t(qua), check.names = FALSE)
d_est$A <- as.factor(d_est$A)
ggplot(data = d_est, aes(x = Y, y = `50%`, ymin = `10%`, ymax = `90%`, shape = A, fill = A)) +
  theme_bw(base_size = 18) + theme(legend.key.height = grid::unit(2.5,'line')) +
  coord_fixed(ratio = 1, xlim = c(5, 70), ylim = c(5, 70)) +
  geom_pointrange(size = 0.5, color = 'grey5') +
  geom_abline(aes(slope = 1, intercept = 0), color = 'black', alpha = 3/5, linetype = 'dashed') +
  scale_shape_manual(values = c(21, 24)) +
  scale_fill_manual(values = c('white', 'grey70')) +
  labs(x = 'Observed', y = 'Predicted') +
  scale_x_continuous(breaks = seq(from = 0, to = 70, by = 20)) +
  scale_y_continuous(breaks = seq(from = 0, to = 70, by = 20)) +
  facet_grid(~ A)
```

## 5.3.5 モデル式の記述

次はロジスティック回帰モデルを扱う。使用されているデータは学生ごとに集計されたものではなく、1出席ごとに情報が記録されているデータ。

出席1行ごとに独立に確率分布から生成され、出席確率$q$は、線形結合$b_{1} + b_{2}A[n] + b_{3}Score[n] + b_{4}Weather[i]$をロジスティック関数で変換することで決まり、その$q$をパラメタとするベルヌイ分布に従って$Y$が生成されると仮定する。

<div class="tbox">
<th3>モデル5-5</th3>
<div class="inner">
$$
\begin{eqnarray}
q[i] &=& inv\_logit(b_{1} + b_{2}A[i] + b_{3}Score[i] + b_{4}Weather[i])  \\
Y[i] &\sim& Bernoulli(q[i])
\end{eqnarray}
$$
</div>
</div>

書籍でも指摘されているように、学生の出席行動が考慮されていないため、この仮定をおくことは少し無理がある。

```
data {
  int I;
  int<lower=0, upper=1> A[I];
  real<lower=0, upper=1> Score[I];
  real<lower=0, upper=1> W[I];
  int<lower=0, upper=1> Y[I];
}

parameters {
  real b[4];
}

transformed parameters {
  real q[I];
  for (i in 1:I){
    q[i] = inv_logit(b[1] + b[2]*A[i] + b[3]*Score[i] + b[4]*W[i]);
  }
}

model {
  for (i in 1:I){
    Y[i] ~ bernoulli(q[i]);
  }
}
```

Stanモデルの定義も終わっているので、書籍内で使用されているデータを利用して分析を実行する。

```{r}
d <- read.csv('https://raw.githubusercontent.com/MatsuuraKentaro/RStanBook/master/chap05/input/data-attendance-3.txt')
conv <- c(0, 0.2, 1)
names(conv) <- c('A', 'B', 'C')
data <- list(I = nrow(d), A = d$A, Score = d$Score/200, W = conv[d$Weather], Y = d$Y)
str(data)
```

ここでは、`stan_model()`関数で最初にコンパイルしておいてから、

```{r, eval=TRUE, echo=TRUE, results='hide'}
model535 <- stan_model('note_ahirubayes031.stan')
```

`sampling()`関数でサンプリングする。

```{r, eval=TRUE, echo=TRUE, results='hide'}
fit <- sampling(object = model535, data = data, seed = 1234)
```

推定結果はこちら。

```{r, class.output="scroll-1000"}
print(fit, prob = c(0.025, 0.5, 0.975), digits_summary = 1)
```

## 5.3.7 図によるモデルのチェック

このモデルでは`b[4]`という形でベータをベクトルで指定したため、いつもと保存のされ方が異なり、列ごとに各ベータのMCMCサンプルが保存されている。

```{r}
ms <- rstan::extract(fit)
logistic <- function(x) 1/(1+exp(-x))
head(ms$b)
```

書籍の条件通り、アルバイトが好きではない`A=0`、晴れ`W=0`より`b2,b4`は計算に含める必要がない。あとはスコア1点ごとに、各ベータの値4000個すべてを利用して`q_mcmc`を計算し、パーセンタイルを計算する。これをスコアの長さ分、繰り返す。

```{r}
X <- 30:200
# 1:length(X)は1-171を返すが、スケーリングしているため、1が30に対応することになる
q_qua <- logistic(t(
  sapply(1:length(X), function(i) {
    q_mcmc <- ms$b[,1] + ms$b[,3]*X[i]/200
    quantile(q_mcmc, probs = c(0.1, 0.5, 0.9))}
  )
))
d_est <- data.frame(X, q_qua, check.names = FALSE)
d$A <- as.factor(d$A)

ggplot(d_est, aes(x = X, y = `50%`)) +
  theme_bw(base_size = 18) +
  geom_ribbon(aes(ymin = `10%`, ymax = `90%`), fill = 'black', alpha = 2/6) +
  geom_line(size = 1) +
  geom_point(data = subset(d, A == 0 & Weather == 'A'), aes(x = Score, y = Y, color = A),
             position = position_jitter(w = 0, h = 0.1), size = 0.5) +
  labs(x = 'Score', y = 'q') +
  scale_color_manual(values = c('black')) +
  scale_y_continuous(breaks = seq(0, 1, 0.2)) +
  xlim(30, 200)
```

観測値と予測分布の散布図に似ている図は01のデータでは扱いにくい。そのため、バイオリンプロットを利用した作図が提案されている。横軸は`q[i]`の事後分布の中央値、縦軸に`Y[i]`を取るプロットのこと。`q[i]`が小さい時は、`Y=0`に点が集中し、`q[i]`が大きい時は、`Y=1`に点が集中すれば、モデルの予測が上手くできていると考えることが可能。`ms$q`にはMCMCサンプル4000行、2396出席ごとの`q`が列として保存されているため、これを利用する。

```{r}
qua <- apply(ms$q, 2, quantile, prob = c(0.1, 0.5, 0.9))
d_est <- data.frame(d, t(qua), check.names = FALSE)
d_est$Y <- as.factor(d_est$Y)
d_est$A <- as.factor(d_est$A)

ggplot(data = d_est, aes(x = Y, y = `50%`)) +
  theme_bw(base_size = 18) +
  coord_flip() +
  geom_violin(trim = FALSE, size = 1, color = 'grey80') +
  geom_point(aes(color = A), position = position_jitter(w = 0.3, h = 0), size = 0.5) +
  scale_color_manual(values = c('grey5', 'grey50')) +
  labs(x = 'Y', y = 'q')
```

## 5.4.1 メカニズムの想像

次はポアソン回帰モデルを扱う。使用されているデータは学生ごとに集計されたデータで、二項ロジスティック回帰モデルの時に使用したデータ。

総授業回数$M$に与えるアルバイトやスコアの関係性を分析する。この時に問題となるのは、総授業回数$M$はマイナスを取ることはないため、総授業回数$M$がマイナスを取らないように指数変換を行う。つまり、説明変数の線形結合を0以上の範囲に変換し、平均授業回数$\lambda$を決める。そして、平均授業回数$\lambda$をパラメタとするポアソン分布に従って、総授業回数$M$が生成されたと仮定する。

## 5.4.2 モデル式の記述

1人の学生ごとに独立に総授業回数$M[n]$は$\lambda[n]$を持つポアソン分布から生成されたと仮定する。

<div class="tbox">
<th3>モデル5-6</th3>
<div class="inner">
$$
\begin{eqnarray}
\lambda[n] &=& exp(b_{1} + b_{2}A[n] + b_{3}Score[n])  \\
M[n] &\sim& Poisson(\lambda[n])
\end{eqnarray}
$$
</div>
</div>

上記のモデルをStanファイルに記述する。

```
data {
  int N;
  int<lower=0, upper=1> A[N];
  real<lower=0, upper=1> Score[N];
  int<lower=0> M[N];
}

parameters {
  real b[3];
}

transformed parameters {
  real lambda[N];
  for (n in 1:N){
    lambda[n] = exp(b[1] + b[2]*A[n] + b[3]*Score[n]);
  }
}

model {
  for (n in 1:N){
    M[n] ~ poisson(lambda[n]);
  }
}

generated quantities {
  real m_pred[N];
  for (n in 1:N)
    m_pred[n] = poisson_rng(lambda[n]);
}
```

Stanモデルの定義も終わっているので、書籍内で使用されているデータを利用して分析を実行する。

```{r}
d <- read.csv('https://raw.githubusercontent.com/MatsuuraKentaro/RStanBook/master/chap05/input/data-attendance-2.txt')
data <- list(N = nrow(d), A = d$A, Score = d$Score/200, M = d$M)
str(data)
```

ここでは、`stan_model()`関数で最初にコンパイルしておいてから、

```{r, eval=TRUE, echo=TRUE, results='hide'}
model542 <- stan_model('note_ahirubayes032.stan')
```

`sampling()`関数でサンプリングする。

```{r, eval=TRUE, echo=TRUE, results='hide'}
fit <- sampling(object = model542, data = data, seed = 1234)
```

推定結果はこちら。ベータは指数変換をして解釈することになるので、アルバイトの好き嫌いを表す$b[2]$は、$exp(0.26)=1.16$倍となる。つまり、アルバイトが好きな学生の総授業回数$M$は、そうではない学生に比べて1.16倍多い。

```{r, class.output="scroll-1000"}
print(fit, prob = c(0.025, 0.5, 0.975), digits_summary = 1)
```

練習問題5にある通り、図によるモデルのチェックも行っておく。`ms$m_pred`にはMCMCサンプル数4000行、学生50人分の総授業回数$M$の予測分布が保存されているので、パーセンタイルを計算して可視化する。

$M$が低い学生と高い学生の予測分布が`y=x`を含んでおらず、予測があたっていない。アルバイトとスコアの説明変数だけでは説明できないといえる。

```{r}
ms <- rstan::extract(fit)

qua <- apply(ms$m_pred, 2, quantile, prob = c(0.1, 0.5, 0.9))
d_est <- data.frame(d, t(qua), check.names = FALSE)
d_est$A <- as.factor(d_est$A)

ggplot(data = d_est, aes(x = M, y = `50%`, ymin = `10%`, ymax = `90%`, shape = A, fill = A)) +
  coord_fixed(ratio = 1, xlim = c(10, 80), ylim = c(10, 80)) +
  geom_pointrange(size = 0.8) +
  geom_abline(aes(slope = 1, intercept = 0), color = 'black', alpha = 3/5, linetype = '31') +
  scale_shape_manual(values = c(21, 24)) +
  labs(x = 'Observed', y = 'Predicted')
```

## 参考文献および参考資料

- [StanとRでベイズ統計モデリング](https://www.kyoritsu-pub.co.jp/bookdetail/9784320112421)
- [StanとRでベイズ統計モデリング サポートページ](https://github.com/MatsuuraKentaro/RStanBook)
- [Stan Reference Manual](https://mc-stan.org/docs/reference-manual/index.html)